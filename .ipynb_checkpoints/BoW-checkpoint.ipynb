{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "judicial-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "testDataset=json.load(open('test.json'))\n",
    "validDataset=json.load(open('valid.json'))\n",
    "\n",
    "#corpus è l'elenco di tutte le frasi\n",
    "corpus=[]\n",
    "for diz in testDataset:\n",
    "    corpus.append(diz['original_situation'])\n",
    "\n",
    "corpus2=[]\n",
    "for diz in validDataset:\n",
    "    corpus2.append(diz['original_situation'])\n",
    "\n",
    "features = CountVectorizer()\n",
    "features2 = CountVectorizer()\n",
    "count_matrix = features.fit_transform(corpus)\n",
    "count_matrix2 = features2.fit_transform(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "horizontal-virgin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the test.json corpus vocabulary: 2591\n",
      "\n",
      "10 random words from the vocabulary:\n",
      "\t ['really', 'wanted', 'to', 'get', 'the', 'part', 'in', 'school', 'rendition', 'of']\n",
      "\n",
      "Total number of utterance in test.json: 838\n",
      "\n",
      "Total number of words in the valid.json corpus vocabulary: 5161\n",
      "\n",
      "10 random words from the valid.json vocabulary:\n",
      "\t ['felt', 'betrayed', 'when', 'my', 'girlfriend', 'kissed', 'another', 'guy', 'at', 'party']\n",
      "\n",
      "Total number of utterance in valid.json: 3775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Quick look at the results\n",
    "print('Total number of words in the test.json corpus vocabulary: {}\\n'.format(len(features.vocabulary_)))\n",
    "print('10 random words from the vocabulary:\\n\\t {}\\n'.format(list(features.vocabulary_)[0:10]))\n",
    "print('Total number of utterance in test.json: {}\\n'.format(len(corpus)))\n",
    "\n",
    "print('Total number of words in the valid.json corpus vocabulary: {}\\n'.format(len(features2.vocabulary_)))\n",
    "print('10 random words from the valid.json vocabulary:\\n\\t {}\\n'.format(list(features2.vocabulary_)[0:10]))\n",
    "print('Total number of utterance in valid.json: {}\\n'.format(len(corpus2)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "played-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che visualizza la document-term matrix \n",
    "def print_dtm(count_vectorizer_obj, dtm, print_indices):\n",
    "    # print the matrix with words on rows and documents on cols\n",
    "    # read the total number of documents\n",
    "    tot_docs = len(dtm.toarray())\n",
    "    # set the print format\n",
    "    row_format = '{:^5}|' + '{:^15}|' + '{:^8}|'*tot_docs\n",
    "    row_length = 1 + 5 + 15 + 9 * tot_docs+1\n",
    "    # print the header\n",
    "    print('\\n'+'-' * row_length)\n",
    "    doc_names = []\n",
    "    for number in range(tot_docs):\n",
    "        doc_names.append('Doc-{:02d}'.format(number+1))\n",
    "    print(row_format.format('#', 'Word', *doc_names))\n",
    "    print('-' * row_length)\n",
    "    # print the rows\n",
    "    start = print_indices[0]  # index of the first word/feature\n",
    "    end = print_indices[1]  # index of the last word/feature\n",
    "    for i, word, count in zip(range(start, end), count_vectorizer_obj.get_feature_names()[start:end],\n",
    "                              dtm.T.toarray()):\n",
    "        print(row_format.format(i+1, word, *count))\n",
    "    print('-' * row_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "particular-picture",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "  #  |     Word      | Doc-01 | Doc-02 | Doc-03 | Doc-04 | Doc-05 | Doc-06 | Doc-07 | Doc-08 | Doc-09 | Doc-10 |\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "  1  |      10       |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      "  2  |     about     |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      "  3  |   actually    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      "  4  |   affection   |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |\n",
      "  5  |      all      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |\n",
      "  6  |    always     |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      "  7  |      am       |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   2    |\n",
      "  8  |      an       |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      "  9  |      and      |   0    |   2    |   1    |   1    |   0    |   1    |   0    |   2    |   1    |   0    |\n",
      " 10  |     angry     |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 11  |    answers    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 12  |      any      |   0    |   0    |   0    |   1    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      " 13  |      are      |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      " 14  |      as       |   0    |   2    |   1    |   0    |   1    |   1    |   0    |   0    |   0    |   0    |\n",
      " 15  |     asked     |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 16  |     back      |   0    |   1    |   0    |   0    |   0    |   0    |   1    |   1    |   0    |   0    |\n",
      " 17  |      bad      |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      " 18  |      be       |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |\n",
      " 19  |    because    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 20  |    beyond     |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 21  |      big      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |\n",
      " 22  |      bit      |   0    |   0    |   0    |   0    |   1    |   0    |   1    |   0    |   0    |   0    |\n",
      " 23  |      but      |   1    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |\n",
      " 24  |    called     |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 25  |     came      |   0    |   2    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 26  |     cash      |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      " 27  |    certain    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |\n",
      " 28  |   children    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 29  |    choice     |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |\n",
      " 30  |      co       |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 31  |    college    |   0    |   0    |   0    |   0    |   0    |   1    |   1    |   0    |   0    |   0    |\n",
      " 32  |    cursed     |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 33  |      day      |   0    |   0    |   0    |   0    |   1    |   0    |   1    |   1    |   0    |   0    |\n",
      " 34  |      did      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |\n",
      " 35  |     didn      |   0    |   0    |   0    |   1    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      " 36  |      don      |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 37  |     door      |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 38  |    entered    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 39  |    feared     |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 40  |    feeling    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |\n",
      " 41  |     fell      |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 42  |     felt      |   0    |   0    |   0    |   0    |   1    |   1    |   0    |   0    |   0    |   0    |\n",
      " 43  |     first     |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   1    |\n",
      " 44  |     floor     |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 45  |      for      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 46  |    friend     |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 47  |      fun      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 48  |      get      |   1    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 49  |     give      |   0    |   0    |   0    |   0    |   2    |   0    |   0    |   0    |   0    |   0    |\n",
      " 50  |      go       |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |\n",
      " 51  |     going     |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |\n",
      " 52  |      got      |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 53  |    hallway    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 54  |     hard      |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |\n",
      " 55  |     have      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   2    |   0    |\n",
      " 56  |      he       |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |\n",
      " 57  |      her      |   0    |   0    |   0    |   2    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 58  |      him      |   0    |   0    |   0    |   0    |   0    |   1    |   1    |   2    |   0    |   0    |\n",
      " 59  |      his      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 60  |     home      |   0    |   2    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 61  |   homeless    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      " 62  |      in       |   1    |   3    |   1    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      " 63  |   insulted    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 64  |   intruder    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 65  |      it       |   1    |   2    |   1    |   1    |   0    |   1    |   1    |   0    |   0    |   0    |\n",
      " 66  | kindergarten  |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |\n",
      " 67  |     know      |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 68  |      law      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |\n",
      " 69  |     like      |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 70  |    little     |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |\n",
      " 71  |      lot      |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 72  |     love      |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |\n",
      " 73  |     lsat      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |\n",
      " 74  |      mad      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 75  |     made      |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   1    |   0    |   0    |\n",
      " 76  |      man      |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      " 77  |    matched    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |\n",
      " 78  |      me       |   0    |   1    |   0    |   1    |   0    |   0    |   1    |   0    |   0    |   0    |\n",
      " 79  |    meeting    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |\n",
      " 80  |     money     |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      " 81  |     more      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |\n",
      " 82  |    moving     |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |\n",
      " 83  |     much      |   0    |   1    |   0    |   1    |   0    |   1    |   0    |   0    |   0    |   0    |\n",
      " 84  |      my       |   1    |   2    |   0    |   3    |   0    |   1    |   1    |   1    |   0    |   1    |\n",
      " 85  |     name      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 86  |     need      |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      " 87  |   needless    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 88  |   neighbor    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 89  |     next      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |\n",
      " 90  |     night     |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 91  |   nostalgic   |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |\n",
      " 92  |      of       |   1    |   0    |   0    |   3    |   0    |   1    |   1    |   1    |   0    |   1    |\n",
      " 93  |      old      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 94  |      on       |   0    |   0    |   1    |   0    |   1    |   0    |   0    |   0    |   0    |   1    |\n",
      " 95  |      one      |   0    |   1    |   0    |   1    |   1    |   0    |   0    |   1    |   0    |   0    |\n",
      " 96  |    opened     |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 97  |     other     |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |\n",
      " 98  |     over      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |\n",
      " 99  |     part      |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 100 |     past      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |\n",
      " 101 |     plan      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |\n",
      " 102 |     play      |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 103 |   practice    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |\n",
      " 104 |    pretty     |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   1    |\n",
      " 105 |     proud     |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |\n",
      " 106 |   questions   |   0    |   0    |   0    |   2    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 107 |     ready     |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |\n",
      " 108 |    really     |   1    |   0    |   0    |   1    |   1    |   0    |   0    |   0    |   1    |   1    |\n",
      " 109 |   rehearsed   |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |\n",
      " 110 |   rendition   |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 111 |    running    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 112 |      saw      |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 113 |      say      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 114 |    scared     |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 115 |    school     |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |\n",
      " 116 |    seemed     |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 117 |    shadow     |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 118 |      she      |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 119 |     short     |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      " 120 |    slipped    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 121 |      so       |   0    |   1    |   0    |   1    |   1    |   2    |   0    |   1    |   0    |   0    |\n",
      " 122 |   something   |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      " 123 |      son      |   0    |   0    |   0    |   0    |   0    |   1    |   1    |   1    |   0    |   0    |\n",
      " 124 |    started    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |\n",
      " 125 |     store     |   0    |   0    |   2    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 126 |  supervisor   |   0    |   0    |   0    |   2    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 127 |  suspicious   |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 128 |     tall      |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 129 |     that      |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   1    |\n",
      " 130 |      the      |   2    |   2    |   3    |   1    |   0    |   0    |   1    |   0    |   0    |   1    |\n",
      " 131 |     think     |   0    |   0    |   0    |   1    |   0    |   0    |   1    |   0    |   0    |   0    |\n",
      " 132 |     this      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   2    |   0    |\n",
      " 133 |     those     |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      " 134 |    through    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 135 |      to       |   1    |   0    |   1    |   1    |   2    |   1    |   1    |   1    |   2    |   1    |\n",
      " 136 |     told      |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 137 |      try      |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |\n",
      " 138 |    wanted     |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 139 |      was      |   0    |   1    |   1    |   0    |   1    |   3    |   1    |   1    |   0    |   0    |\n",
      " 140 |     wasn      |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |\n",
      " 141 |  wasraining   |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 142 |     week      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   2    |   0    |\n",
      " 143 |    weekend    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |\n",
      " 144 |    weight     |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      " 145 |     weird     |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 146 |     well      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |\n",
      " 147 |     went      |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |   0    |\n",
      " 148 |      wet      |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 149 |     what      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |\n",
      " 150 |     when      |   0    |   0    |   0    |   0    |   0    |   1    |   2    |   0    |   0    |   0    |\n",
      " 151 |     with      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |\n",
      " 152 |    worker     |   0    |   0    |   0    |   1    |   0    |   0    |   0    |   0    |   0    |   0    |\n",
      " 153 |     year      |   0    |   0    |   0    |   0    |   0    |   0    |   0    |   1    |   0    |   0    |\n",
      "----------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giard\\miniconda3\\envs\\smm21\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#voglio visualizzare la document-term matrix delle prime 10 frasi di test.json\n",
    "corpusTest=[]\n",
    "for i in range(10):\n",
    "    corpusTest.append(testDataset[i]['original_situation'])\n",
    "\n",
    "featuresTest = CountVectorizer()\n",
    "count_matrixTest = featuresTest.fit_transform(corpusTest)\n",
    "words_to_print = len(featuresTest.vocabulary_)\n",
    "start_index = 0 # index of the first word/feature to print\n",
    "print_dtm(featuresTest, count_matrixTest, [start_index, start_index+words_to_print])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "failing-information",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Word</th>\n",
       "      <th>V.Mean.Sum</th>\n",
       "      <th>V.SD.Sum</th>\n",
       "      <th>V.Rat.Sum</th>\n",
       "      <th>A.Mean.Sum</th>\n",
       "      <th>A.SD.Sum</th>\n",
       "      <th>A.Rat.Sum</th>\n",
       "      <th>D.Mean.Sum</th>\n",
       "      <th>D.SD.Sum</th>\n",
       "      <th>...</th>\n",
       "      <th>A.Rat.L</th>\n",
       "      <th>A.Mean.H</th>\n",
       "      <th>A.SD.H</th>\n",
       "      <th>A.Rat.H</th>\n",
       "      <th>D.Mean.L</th>\n",
       "      <th>D.SD.L</th>\n",
       "      <th>D.Rat.L</th>\n",
       "      <th>D.Mean.H</th>\n",
       "      <th>D.SD.H</th>\n",
       "      <th>D.Rat.H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>6.26</td>\n",
       "      <td>2.21</td>\n",
       "      <td>19</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1.40</td>\n",
       "      <td>22</td>\n",
       "      <td>4.27</td>\n",
       "      <td>1.75</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.29</td>\n",
       "      <td>11</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1.64</td>\n",
       "      <td>8</td>\n",
       "      <td>4.43</td>\n",
       "      <td>1.99</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>abalone</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1.59</td>\n",
       "      <td>20</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.90</td>\n",
       "      <td>20</td>\n",
       "      <td>4.95</td>\n",
       "      <td>1.79</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.92</td>\n",
       "      <td>8</td>\n",
       "      <td>5.55</td>\n",
       "      <td>2.21</td>\n",
       "      <td>11</td>\n",
       "      <td>4.36</td>\n",
       "      <td>1.03</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>abandon</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1.54</td>\n",
       "      <td>19</td>\n",
       "      <td>3.73</td>\n",
       "      <td>2.43</td>\n",
       "      <td>22</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3.82</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11</td>\n",
       "      <td>2.77</td>\n",
       "      <td>2.09</td>\n",
       "      <td>13</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.93</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>abandonment</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1.74</td>\n",
       "      <td>19</td>\n",
       "      <td>4.95</td>\n",
       "      <td>2.64</td>\n",
       "      <td>21</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1.81</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>5.29</td>\n",
       "      <td>2.63</td>\n",
       "      <td>7</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1.45</td>\n",
       "      <td>16</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.19</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>abbey</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1.69</td>\n",
       "      <td>20</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.70</td>\n",
       "      <td>20</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.92</td>\n",
       "      <td>11</td>\n",
       "      <td>4.83</td>\n",
       "      <td>2.18</td>\n",
       "      <td>18</td>\n",
       "      <td>5.43</td>\n",
       "      <td>1.62</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         Word  V.Mean.Sum  V.SD.Sum  V.Rat.Sum  A.Mean.Sum  \\\n",
       "0           1     aardvark        6.26      2.21         19        2.41   \n",
       "1           2      abalone        5.30      1.59         20        2.65   \n",
       "2           3      abandon        2.84      1.54         19        3.73   \n",
       "3           4  abandonment        2.63      1.74         19        4.95   \n",
       "4           5        abbey        5.85      1.69         20        2.20   \n",
       "\n",
       "   A.SD.Sum  A.Rat.Sum  D.Mean.Sum  D.SD.Sum  ...  A.Rat.L  A.Mean.H  A.SD.H  \\\n",
       "0      1.40         22        4.27      1.75  ...       11      2.55    1.29   \n",
       "1      1.90         20        4.95      1.79  ...       12      2.38    1.92   \n",
       "2      2.43         22        3.32      2.50  ...       11      3.82    2.14   \n",
       "3      2.64         21        2.64      1.81  ...       14      5.29    2.63   \n",
       "4      1.70         20        5.00      2.02  ...        9      2.55    1.92   \n",
       "\n",
       "   A.Rat.H  D.Mean.L  D.SD.L  D.Rat.L  D.Mean.H  D.SD.H  D.Rat.H  \n",
       "0       11      4.12    1.64        8      4.43    1.99        7  \n",
       "1        8      5.55    2.21       11      4.36    1.03       11  \n",
       "2       11      2.77    2.09       13      4.11    2.93        9  \n",
       "3        7      2.31    1.45       16      3.08    2.19       12  \n",
       "4       11      4.83    2.18       18      5.43    1.62        7  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importo lessico del modello\n",
    "import pandas as pd\n",
    "df=pd.read_csv('Ratings_Warriner_et_al.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cathedral-primary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len  vocabulary: 3379\n",
      "\n",
      "10 random words from the vocabulary:\n",
      "\t ['rendition', 'friend', 'got', 'saw', 'tall', 'shadow', 'intruder', 'slipped', 'fell', 'floor']\n",
      "\n",
      "corp: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#BoW parole con  emozioni test.json\n",
    "labelsTest=[]\n",
    "for diz in testDataset:\n",
    "    for label in diz['labels']:\n",
    "        labelsTest.append(label)\n",
    "for diz in validDataset:\n",
    "    for label in diz['labels']:\n",
    "        labelsTest.append(label)\n",
    "\n",
    "delimitatore=\" \"\n",
    "corpusLabelsTest=delimitatore.join(labelsTest)\n",
    "corp=[]\n",
    "corp.append(corpusLabelsTest)\n",
    "featuresEmozioni = CountVectorizer()\n",
    "count_matrixEmozioni = featuresEmozioni.fit_transform(corp)\n",
    "\n",
    "print('len  vocabulary: {}\\n'.format(len(featuresEmozioni.vocabulary_)))\n",
    "print('10 random words from the vocabulary:\\n\\t {}\\n'.format(list(featuresEmozioni.vocabulary_)[0:10]))\n",
    "print('corp: {}\\n'.format(len(corp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sustainable-sellers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giard\\miniconda3\\envs\\smm21\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cat', 49),\n",
       " ('died', 49),\n",
       " ('got', 49),\n",
       " ('home', 50),\n",
       " ('not', 50),\n",
       " ('people', 50),\n",
       " ('money', 51),\n",
       " ('vacation', 52),\n",
       " ('good', 53),\n",
       " ('house', 60),\n",
       " ('away', 61),\n",
       " ('back', 62),\n",
       " ('first', 62),\n",
       " ('son', 66),\n",
       " ('school', 67),\n",
       " ('family', 71),\n",
       " ('passed', 72),\n",
       " ('work', 74),\n",
       " ('old', 76),\n",
       " ('daughter', 77),\n",
       " ('friends', 79),\n",
       " ('girlfriend', 80),\n",
       " ('wife', 80),\n",
       " ('husband', 81),\n",
       " ('new', 88),\n",
       " ('job', 111),\n",
       " ('car', 121),\n",
       " ('friend', 147),\n",
       " ('dog', 152)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(count_matrixEmozioni[0])\n",
    "dizEmozioni={}\n",
    "vocabularioEmozioni = featuresEmozioni.get_feature_names()\n",
    "#print('Word\\t--\\tCount')\n",
    "for word, count in zip(vocabularioEmozioni, count_matrixEmozioni.toarray()[0]):\n",
    "  #  print('{}\\t--\\t{}'.format(word, count))\n",
    "    dizEmozioni[word]=count\n",
    "#print('')\n",
    "#dizEmozioni\n",
    "import operator\n",
    "sortedDict = sorted(dizEmozioni.items(), key=operator.itemgetter(1))\n",
    "print(len(sortedDict))\n",
    "sortedDict[3350:]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
